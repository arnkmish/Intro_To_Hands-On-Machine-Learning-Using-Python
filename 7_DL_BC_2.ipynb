{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os \n",
    "dirs= os.listdir(\"/content/drive/My Drive/GUIST_Webinar_Files/Jupyter_Notebook_Codes/Data\")\n",
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing data\n",
    "data = pd.read_csv('/content/drive/My Drive/GUIST_Webinar_Files/Jupyter_Notebook_Codes/Data/BCCD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>70</td>\n",
       "      <td>2.707</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>8.8071</td>\n",
       "      <td>9.702400</td>\n",
       "      <td>7.99585</td>\n",
       "      <td>417.114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>20.690495</td>\n",
       "      <td>92</td>\n",
       "      <td>3.115</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>5.429285</td>\n",
       "      <td>4.06405</td>\n",
       "      <td>468.786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>23.124670</td>\n",
       "      <td>91</td>\n",
       "      <td>4.498</td>\n",
       "      <td>1.009651</td>\n",
       "      <td>17.9393</td>\n",
       "      <td>22.432040</td>\n",
       "      <td>9.27715</td>\n",
       "      <td>554.697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>21.367521</td>\n",
       "      <td>77</td>\n",
       "      <td>3.226</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>9.8827</td>\n",
       "      <td>7.169560</td>\n",
       "      <td>12.76600</td>\n",
       "      <td>928.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>92</td>\n",
       "      <td>3.549</td>\n",
       "      <td>0.805386</td>\n",
       "      <td>6.6994</td>\n",
       "      <td>4.819240</td>\n",
       "      <td>10.57635</td>\n",
       "      <td>773.920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        BMI  Glucose  Insulin      HOMA   Leptin  Adiponectin  Resistin  \\\n",
       "0   48  23.500000       70    2.707  0.467409   8.8071     9.702400   7.99585   \n",
       "1   83  20.690495       92    3.115  0.706897   8.8438     5.429285   4.06405   \n",
       "2   82  23.124670       91    4.498  1.009651  17.9393    22.432040   9.27715   \n",
       "3   68  21.367521       77    3.226  0.612725   9.8827     7.169560  12.76600   \n",
       "4   86  21.111111       92    3.549  0.805386   6.6994     4.819240  10.57635   \n",
       "\n",
       "     MCP.1  Classification  \n",
       "0  417.114               1  \n",
       "1  468.786               1  \n",
       "2  554.697               1  \n",
       "3  928.220               1  \n",
       "4  773.920               1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if we have read the data correctly or not.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age               0\n",
      "BMI               0\n",
      "Glucose           0\n",
      "Insulin           0\n",
      "HOMA              0\n",
      "Leptin            0\n",
      "Adiponectin       0\n",
      "Resistin          0\n",
      "MCP.1             0\n",
      "Classification    0\n",
      "dtype: int64\n",
      "Age               0\n",
      "BMI               0\n",
      "Glucose           0\n",
      "Insulin           0\n",
      "HOMA              0\n",
      "Leptin            0\n",
      "Adiponectin       0\n",
      "Resistin          0\n",
      "MCP.1             0\n",
      "Classification    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for Missing values\n",
    "print(data.isnull().sum())\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[48.0,\n",
       "  23.5,\n",
       "  70.0,\n",
       "  2.707,\n",
       "  0.46740866700000006,\n",
       "  8.8071,\n",
       "  9.7024,\n",
       "  7.99585,\n",
       "  417.11400000000003],\n",
       " [83.0,\n",
       "  20.69049454,\n",
       "  92.0,\n",
       "  3.115,\n",
       "  0.706897333,\n",
       "  8.8438,\n",
       "  5.429285,\n",
       "  4.06405,\n",
       "  468.786],\n",
       " [82.0,\n",
       "  23.12467037,\n",
       "  91.0,\n",
       "  4.498,\n",
       "  1.009651067,\n",
       "  17.9393,\n",
       "  22.43204,\n",
       "  9.27715,\n",
       "  554.697],\n",
       " [68.0,\n",
       "  21.36752137,\n",
       "  77.0,\n",
       "  3.2260000000000004,\n",
       "  0.612724933,\n",
       "  9.8827,\n",
       "  7.169560000000001,\n",
       "  12.765999999999998,\n",
       "  928.22],\n",
       " [86.0,\n",
       "  21.11111111,\n",
       "  92.0,\n",
       "  3.549,\n",
       "  0.8053864000000001,\n",
       "  6.6994,\n",
       "  4.81924,\n",
       "  10.57635,\n",
       "  773.92],\n",
       " [49.0,\n",
       "  22.85445769,\n",
       "  92.0,\n",
       "  3.2260000000000004,\n",
       "  0.7320869329999999,\n",
       "  6.8317,\n",
       "  13.67975,\n",
       "  10.3176,\n",
       "  530.41],\n",
       " [89.0,\n",
       "  22.7,\n",
       "  77.0,\n",
       "  4.69,\n",
       "  0.890787333,\n",
       "  6.9639999999999995,\n",
       "  5.5898650000000005,\n",
       "  12.9361,\n",
       "  1256.083],\n",
       " [76.0,\n",
       "  23.8,\n",
       "  118.0,\n",
       "  6.47,\n",
       "  1.8832013330000001,\n",
       "  4.311,\n",
       "  13.251320000000002,\n",
       "  5.1042,\n",
       "  280.694],\n",
       " [73.0, 22.0, 97.0, 3.35, 0.801543333, 4.47, 10.358725, 6.28445, 136.855],\n",
       " [75.0, 23.0, 83.0, 4.952, 1.013839467, 17.127, 11.57899, 7.0913, 318.302],\n",
       " [34.0, 21.47, 78.0, 3.469, 0.6674356, 14.57, 13.11, 6.92, 354.6],\n",
       " [29.0,\n",
       "  23.01,\n",
       "  82.0,\n",
       "  5.662999999999999,\n",
       "  1.145436133,\n",
       "  35.59,\n",
       "  26.72,\n",
       "  4.58,\n",
       "  174.8],\n",
       " [25.0, 22.86, 82.0, 4.09, 0.8272706670000001, 20.45, 23.67, 5.14, 313.73],\n",
       " [24.0, 18.67, 88.0, 6.107, 1.33, 8.88, 36.06, 6.85, 632.22],\n",
       " [38.0, 23.34, 75.0, 5.782, 1.0696700000000001, 15.26, 17.95, 9.35, 165.02],\n",
       " [44.0, 20.76, 86.0, 7.553, 1.6, 14.09, 20.32, 7.64, 63.61],\n",
       " [47.0, 22.03, 84.0, 2.8689999999999998, 0.59, 26.65, 38.04, 3.32, 191.72],\n",
       " [61.0,\n",
       "  32.03895937,\n",
       "  85.0,\n",
       "  18.077,\n",
       "  3.790144333,\n",
       "  30.7729,\n",
       "  7.780255,\n",
       "  13.68392,\n",
       "  444.395],\n",
       " [64.0,\n",
       "  34.529722799999995,\n",
       "  95.0,\n",
       "  4.427,\n",
       "  1.0373936670000001,\n",
       "  21.2117,\n",
       "  5.462619999999999,\n",
       "  6.70188,\n",
       "  252.449],\n",
       " [32.0,\n",
       "  36.51263743,\n",
       "  87.0,\n",
       "  14.026,\n",
       "  3.0099796000000003,\n",
       "  49.3727,\n",
       "  5.1,\n",
       "  17.10223,\n",
       "  588.46],\n",
       " [36.0, 28.57667585, 86.0, 4.345, 0.921719333, 15.1248, 8.6, 9.1539, 534.224],\n",
       " [34.0,\n",
       "  31.97501487,\n",
       "  87.0,\n",
       "  4.53,\n",
       "  0.972138,\n",
       "  28.7502,\n",
       "  7.642760000000001,\n",
       "  5.62592,\n",
       "  572.783],\n",
       " [29.0,\n",
       "  32.27078777,\n",
       "  84.0,\n",
       "  5.81,\n",
       "  1.203832,\n",
       "  45.6196,\n",
       "  6.209635,\n",
       "  24.6033,\n",
       "  904.9810000000001],\n",
       " [35.0,\n",
       "  30.27681661,\n",
       "  84.0,\n",
       "  4.376,\n",
       "  0.9067072,\n",
       "  39.2134,\n",
       "  9.048185,\n",
       "  16.43706,\n",
       "  733.797],\n",
       " [54.0,\n",
       "  30.48315806,\n",
       "  90.0,\n",
       "  5.537000000000001,\n",
       "  1.229214,\n",
       "  12.331,\n",
       "  9.73138,\n",
       "  10.19299,\n",
       "  1227.91],\n",
       " [45.0,\n",
       "  37.03560819,\n",
       "  83.0,\n",
       "  6.76,\n",
       "  1.3839973330000002,\n",
       "  39.9802,\n",
       "  4.617125,\n",
       "  8.70448,\n",
       "  586.173],\n",
       " [50.0,\n",
       "  38.57875854,\n",
       "  106.0,\n",
       "  6.702999999999999,\n",
       "  1.752611067,\n",
       "  46.6401,\n",
       "  4.667644999999999,\n",
       "  11.78388,\n",
       "  887.16],\n",
       " [66.0,\n",
       "  31.44654088,\n",
       "  90.0,\n",
       "  9.245,\n",
       "  2.05239,\n",
       "  45.9624,\n",
       "  10.355260000000001,\n",
       "  23.3819,\n",
       "  1102.11],\n",
       " [35.0,\n",
       "  35.250761100000005,\n",
       "  90.0,\n",
       "  6.817,\n",
       "  1.513374,\n",
       "  50.6094,\n",
       "  6.966895,\n",
       "  22.037029999999998,\n",
       "  667.928],\n",
       " [36.0,\n",
       "  34.174890000000005,\n",
       "  80.0,\n",
       "  6.59,\n",
       "  1.300426667,\n",
       "  10.2809,\n",
       "  5.065915,\n",
       "  15.721870000000001,\n",
       "  581.313],\n",
       " [66.0,\n",
       "  36.21227888,\n",
       "  101.0,\n",
       "  15.533,\n",
       "  3.869788067,\n",
       "  74.7069,\n",
       "  7.53955,\n",
       "  22.32024,\n",
       "  864.9680000000001],\n",
       " [53.0,\n",
       "  36.7901662,\n",
       "  101.0,\n",
       "  10.175,\n",
       "  2.534931667,\n",
       "  27.1841,\n",
       "  20.03,\n",
       "  10.26309,\n",
       "  695.7539999999999],\n",
       " [28.0,\n",
       "  35.85581466,\n",
       "  87.0,\n",
       "  8.576,\n",
       "  1.8404096,\n",
       "  68.5102,\n",
       "  4.7942,\n",
       "  21.44366,\n",
       "  358.624],\n",
       " [43.0,\n",
       "  34.42217362,\n",
       "  89.0,\n",
       "  23.194000000000003,\n",
       "  5.091856133,\n",
       "  31.2128,\n",
       "  8.300955,\n",
       "  6.710260000000001,\n",
       "  960.2460000000001],\n",
       " [51.0,\n",
       "  27.68877813,\n",
       "  77.0,\n",
       "  3.855,\n",
       "  0.732193,\n",
       "  20.092,\n",
       "  3.1920900000000003,\n",
       "  10.37518,\n",
       "  473.85900000000004],\n",
       " [67.0,\n",
       "  29.60676726,\n",
       "  79.0,\n",
       "  5.819,\n",
       "  1.1339291329999999,\n",
       "  21.9033,\n",
       "  2.19428,\n",
       "  4.2075,\n",
       "  585.307],\n",
       " [66.0,\n",
       "  31.2385898,\n",
       "  82.0,\n",
       "  4.181,\n",
       "  0.845676933,\n",
       "  16.2247,\n",
       "  4.267105,\n",
       "  3.29175,\n",
       "  634.602],\n",
       " [69.0,\n",
       "  35.09270153,\n",
       "  101.0,\n",
       "  5.646,\n",
       "  1.4066068,\n",
       "  83.4821,\n",
       "  6.796985,\n",
       "  82.1,\n",
       "  263.499],\n",
       " [60.0,\n",
       "  26.34929208,\n",
       "  103.0,\n",
       "  5.138,\n",
       "  1.305394533,\n",
       "  24.2998,\n",
       "  2.19428,\n",
       "  20.2535,\n",
       "  378.996],\n",
       " [77.0,\n",
       "  35.58792924,\n",
       "  76.0,\n",
       "  3.8810000000000002,\n",
       "  0.7275581329999999,\n",
       "  21.7863,\n",
       "  8.12555,\n",
       "  17.2615,\n",
       "  618.2719999999999],\n",
       " [76.0,\n",
       "  29.2184076,\n",
       "  83.0,\n",
       "  5.376,\n",
       "  1.1006464,\n",
       "  28.561999999999998,\n",
       "  7.369960000000001,\n",
       "  8.04375,\n",
       "  698.789],\n",
       " [76.0,\n",
       "  27.2,\n",
       "  94.0,\n",
       "  14.07,\n",
       "  3.262364,\n",
       "  35.891,\n",
       "  9.346630000000001,\n",
       "  8.4156,\n",
       "  377.227],\n",
       " [75.0,\n",
       "  27.3,\n",
       "  85.0,\n",
       "  5.197,\n",
       "  1.089637667,\n",
       "  10.39,\n",
       "  9.000805,\n",
       "  7.5767,\n",
       "  335.39300000000003],\n",
       " [69.0, 32.5, 93.0, 5.43, 1.245642, 15.145, 11.78796, 11.78796, 270.142],\n",
       " [71.0,\n",
       "  30.3,\n",
       "  102.0,\n",
       "  8.34,\n",
       "  2.098344,\n",
       "  56.501999999999995,\n",
       "  8.13,\n",
       "  4.2989,\n",
       "  200.976],\n",
       " [66.0,\n",
       "  27.7,\n",
       "  90.0,\n",
       "  6.042000000000001,\n",
       "  1.341324,\n",
       "  24.846,\n",
       "  7.652055000000001,\n",
       "  6.7052,\n",
       "  225.88],\n",
       " [75.0,\n",
       "  25.7,\n",
       "  94.0,\n",
       "  8.079,\n",
       "  1.8732508,\n",
       "  65.926,\n",
       "  3.7412199999999998,\n",
       "  4.49685,\n",
       "  206.80200000000002],\n",
       " [78.0,\n",
       "  25.3,\n",
       "  60.0,\n",
       "  3.508,\n",
       "  0.519184,\n",
       "  6.632999999999999,\n",
       "  10.567295,\n",
       "  4.6638,\n",
       "  209.74900000000002],\n",
       " [69.0, 29.4, 89.0, 10.704, 2.3498848, 45.272, 8.2863, 4.53, 215.769],\n",
       " [85.0,\n",
       "  26.6,\n",
       "  96.0,\n",
       "  4.462,\n",
       "  1.0566016000000003,\n",
       "  7.85,\n",
       "  7.9317,\n",
       "  9.6135,\n",
       "  232.00599999999997],\n",
       " [76.0,\n",
       "  27.1,\n",
       "  110.0,\n",
       "  26.211,\n",
       "  7.111917999999999,\n",
       "  21.778000000000002,\n",
       "  4.9356349999999996,\n",
       "  8.49395,\n",
       "  45.843],\n",
       " [77.0,\n",
       "  25.9,\n",
       "  85.0,\n",
       "  4.58,\n",
       "  0.960273333,\n",
       "  13.74,\n",
       "  9.753260000000001,\n",
       "  11.774000000000001,\n",
       "  488.829],\n",
       " [45.0,\n",
       "  21.30394858,\n",
       "  102.0,\n",
       "  13.852,\n",
       "  3.4851632000000006,\n",
       "  7.6476,\n",
       "  21.056625,\n",
       "  23.03408,\n",
       "  552.444],\n",
       " [45.0,\n",
       "  20.82999519,\n",
       "  74.0,\n",
       "  4.56,\n",
       "  0.8323520000000001,\n",
       "  7.7529,\n",
       "  8.237405,\n",
       "  28.0323,\n",
       "  382.955],\n",
       " [49.0,\n",
       "  20.9566075,\n",
       "  94.0,\n",
       "  12.305,\n",
       "  2.853119333,\n",
       "  11.2406,\n",
       "  8.412175,\n",
       "  23.1177,\n",
       "  573.63],\n",
       " [34.0,\n",
       "  24.24242424,\n",
       "  92.0,\n",
       "  21.699,\n",
       "  4.9242264,\n",
       "  16.7353,\n",
       "  21.823745000000002,\n",
       "  12.065339999999999,\n",
       "  481.949],\n",
       " [42.0,\n",
       "  21.35991456,\n",
       "  93.0,\n",
       "  2.9989999999999997,\n",
       "  0.6879706,\n",
       "  19.0826,\n",
       "  8.462914999999999,\n",
       "  17.37615,\n",
       "  321.91900000000004],\n",
       " [68.0,\n",
       "  21.08281329,\n",
       "  102.0,\n",
       "  6.2,\n",
       "  1.55992,\n",
       "  9.6994,\n",
       "  8.574655,\n",
       "  13.74244,\n",
       "  448.79900000000004],\n",
       " [51.0, 19.13265306, 93.0, 4.364, 1.0011016, 11.0816, 5.80762, 5.57055, 90.6],\n",
       " [62.0,\n",
       "  22.65625,\n",
       "  92.0,\n",
       "  3.4819999999999998,\n",
       "  0.790181867,\n",
       "  9.8648,\n",
       "  11.236235,\n",
       "  10.69548,\n",
       "  703.9730000000001],\n",
       " [38.0,\n",
       "  22.4996371,\n",
       "  95.0,\n",
       "  5.261,\n",
       "  1.232827667,\n",
       "  8.437999999999999,\n",
       "  4.77192,\n",
       "  15.73606,\n",
       "  199.055],\n",
       " [69.0,\n",
       "  21.51385851,\n",
       "  112.0,\n",
       "  6.683,\n",
       "  1.846290133,\n",
       "  32.58,\n",
       "  4.138025,\n",
       "  15.69876,\n",
       "  713.2389999999999],\n",
       " [49.0,\n",
       "  21.36752137,\n",
       "  78.0,\n",
       "  2.64,\n",
       "  0.5079359999999999,\n",
       "  6.3339,\n",
       "  3.8861449999999995,\n",
       "  22.94254,\n",
       "  737.672],\n",
       " [51.0,\n",
       "  22.89281998,\n",
       "  103.0,\n",
       "  2.74,\n",
       "  0.696142667,\n",
       "  8.0163,\n",
       "  9.349775,\n",
       "  11.55492,\n",
       "  359.23199999999997],\n",
       " [59.0,\n",
       "  22.83287935,\n",
       "  98.0,\n",
       "  6.862,\n",
       "  1.658774133,\n",
       "  14.9037,\n",
       "  4.230105,\n",
       "  8.2049,\n",
       "  355.31],\n",
       " [45.0,\n",
       "  23.14049587,\n",
       "  116.0,\n",
       "  4.902,\n",
       "  1.4026256000000001,\n",
       "  17.9973,\n",
       "  4.294705,\n",
       "  5.2633,\n",
       "  518.586],\n",
       " [54.0,\n",
       "  24.21875,\n",
       "  86.0,\n",
       "  3.73,\n",
       "  0.791257333,\n",
       "  8.6874,\n",
       "  3.7052300000000002,\n",
       "  10.34455,\n",
       "  635.049],\n",
       " [64.0,\n",
       "  22.22222222,\n",
       "  98.0,\n",
       "  5.7,\n",
       "  1.37788,\n",
       "  12.1905,\n",
       "  4.7839849999999995,\n",
       "  13.91245,\n",
       "  395.976],\n",
       " [46.0, 20.83, 88.0, 3.42, 0.742368, 12.87, 18.55, 13.56, 301.21],\n",
       " [44.0, 19.56, 114.0, 15.89, 4.468268, 13.08, 20.37, 4.62, 220.66],\n",
       " [45.0, 20.26, 92.0, 3.44, 0.7806506670000001, 7.65, 16.67, 7.84, 193.87],\n",
       " [44.0, 24.74, 106.0, 58.46, 15.28534133, 18.16, 16.1, 5.31, 244.75],\n",
       " [51.0, 18.37, 105.0, 6.03, 1.56177, 9.62, 12.76, 3.21, 513.66],\n",
       " [72.0, 23.62, 105.0, 4.42, 1.14478, 21.78, 17.86, 4.82, 195.94],\n",
       " [46.0, 22.21, 86.0, 36.94, 7.836205333, 10.16, 9.76, 5.68, 312.0],\n",
       " [43.0,\n",
       "  26.5625,\n",
       "  101.0,\n",
       "  10.555,\n",
       "  2.6296023330000002,\n",
       "  9.8,\n",
       "  6.420294999999999,\n",
       "  16.1,\n",
       "  806.7239999999999],\n",
       " [55.0,\n",
       "  31.97501487,\n",
       "  92.0,\n",
       "  16.635,\n",
       "  3.775036,\n",
       "  37.2234,\n",
       "  11.018455,\n",
       "  7.165139999999999,\n",
       "  483.37699999999995],\n",
       " [43.0,\n",
       "  31.25,\n",
       "  103.0,\n",
       "  4.328,\n",
       "  1.099600533,\n",
       "  25.7816,\n",
       "  12.718960000000001,\n",
       "  38.6531,\n",
       "  775.322],\n",
       " [86.0,\n",
       "  26.66666667,\n",
       "  201.0,\n",
       "  41.611000000000004,\n",
       "  20.6307338,\n",
       "  47.647,\n",
       "  5.3571349999999995,\n",
       "  24.3701,\n",
       "  1698.44],\n",
       " [41.0,\n",
       "  26.672763300000003,\n",
       "  97.0,\n",
       "  22.033,\n",
       "  5.271762467,\n",
       "  44.7059,\n",
       "  13.494864999999999,\n",
       "  27.8325,\n",
       "  783.796],\n",
       " [59.0,\n",
       "  28.67262608,\n",
       "  77.0,\n",
       "  3.188,\n",
       "  0.605507467,\n",
       "  17.022000000000002,\n",
       "  16.440479999999997,\n",
       "  31.6904,\n",
       "  910.4889999999999],\n",
       " [81.0,\n",
       "  31.64036818,\n",
       "  100.0,\n",
       "  9.669,\n",
       "  2.38502,\n",
       "  38.8066,\n",
       "  10.636525,\n",
       "  29.5583,\n",
       "  426.175],\n",
       " [48.0,\n",
       "  32.46191136,\n",
       "  99.0,\n",
       "  28.677,\n",
       "  7.002923399999999,\n",
       "  46.076,\n",
       "  21.57,\n",
       "  10.15726,\n",
       "  738.034],\n",
       " [71.0,\n",
       "  25.51020408,\n",
       "  112.0,\n",
       "  10.395,\n",
       "  2.8717919999999997,\n",
       "  19.0653,\n",
       "  5.4861,\n",
       "  42.7447,\n",
       "  799.898],\n",
       " [42.0,\n",
       "  29.296875,\n",
       "  98.0,\n",
       "  4.172,\n",
       "  1.008511467,\n",
       "  12.2617,\n",
       "  6.695585,\n",
       "  53.6717,\n",
       "  1041.843],\n",
       " [65.0,\n",
       "  29.666548,\n",
       "  85.0,\n",
       "  14.649000000000001,\n",
       "  3.0714069999999998,\n",
       "  26.5166,\n",
       "  7.28287,\n",
       "  19.46324,\n",
       "  1698.44],\n",
       " [48.0, 28.125, 90.0, 2.54, 0.56388, 15.5325, 10.22231, 16.11032, 1698.44],\n",
       " [85.0,\n",
       "  27.68877813,\n",
       "  196.0,\n",
       "  51.81399999999999,\n",
       "  25.05034187,\n",
       "  70.8824,\n",
       "  7.9016850000000005,\n",
       "  55.2153,\n",
       "  1078.359],\n",
       " [48.0,\n",
       "  31.25,\n",
       "  199.0,\n",
       "  12.162,\n",
       "  5.9699204,\n",
       "  18.1314,\n",
       "  4.104105000000001,\n",
       "  53.6308,\n",
       "  1698.44],\n",
       " [58.0,\n",
       "  29.15451895,\n",
       "  139.0,\n",
       "  16.582,\n",
       "  5.685415067,\n",
       "  22.8884,\n",
       "  10.26266,\n",
       "  13.973989999999999,\n",
       "  923.8860000000001],\n",
       " [40.0,\n",
       "  30.83653053,\n",
       "  128.0,\n",
       "  41.894,\n",
       "  13.22733227,\n",
       "  31.0385,\n",
       "  6.160995,\n",
       "  17.55503,\n",
       "  638.261],\n",
       " [82.0,\n",
       "  31.21748179,\n",
       "  100.0,\n",
       "  18.077,\n",
       "  4.4589933330000004,\n",
       "  31.6453,\n",
       "  9.92365,\n",
       "  19.94687,\n",
       "  994.316],\n",
       " [52.0,\n",
       "  30.801248699999995,\n",
       "  87.0,\n",
       "  30.212,\n",
       "  6.4834952,\n",
       "  29.2739,\n",
       "  6.26854,\n",
       "  24.245910000000002,\n",
       "  764.6669999999999],\n",
       " [49.0,\n",
       "  32.46191136,\n",
       "  134.0,\n",
       "  24.886999999999997,\n",
       "  8.225983067,\n",
       "  42.3914,\n",
       "  10.79394,\n",
       "  5.768,\n",
       "  656.393],\n",
       " [60.0,\n",
       "  31.23140988,\n",
       "  131.0,\n",
       "  30.13,\n",
       "  9.736007333,\n",
       "  37.843,\n",
       "  8.40443,\n",
       "  11.50005,\n",
       "  396.02099999999996],\n",
       " [49.0,\n",
       "  29.77777778,\n",
       "  70.0,\n",
       "  8.396,\n",
       "  1.4497093330000002,\n",
       "  51.3387,\n",
       "  10.73174,\n",
       "  20.76801,\n",
       "  602.486],\n",
       " [44.0,\n",
       "  27.88761707,\n",
       "  99.0,\n",
       "  9.208,\n",
       "  2.2485936,\n",
       "  12.6757,\n",
       "  5.4781699999999995,\n",
       "  23.03306,\n",
       "  407.20599999999996],\n",
       " [40.0,\n",
       "  27.63605442,\n",
       "  103.0,\n",
       "  2.432,\n",
       "  0.617890133,\n",
       "  14.3224,\n",
       "  6.783869999999999,\n",
       "  26.0136,\n",
       "  293.123],\n",
       " [71.0,\n",
       "  27.91551882,\n",
       "  104.0,\n",
       "  18.2,\n",
       "  4.668906667,\n",
       "  53.4997,\n",
       "  1.65602,\n",
       "  49.24184,\n",
       "  256.001],\n",
       " [69.0,\n",
       "  28.44444444,\n",
       "  108.0,\n",
       "  8.808,\n",
       "  2.3464512,\n",
       "  14.7485,\n",
       "  5.288025,\n",
       "  16.48508,\n",
       "  353.56800000000004],\n",
       " [74.0,\n",
       "  28.65013774,\n",
       "  88.0,\n",
       "  3.012,\n",
       "  0.6538048000000001,\n",
       "  31.1233,\n",
       "  7.65222,\n",
       "  18.35574,\n",
       "  572.401],\n",
       " [66.0,\n",
       "  26.5625,\n",
       "  89.0,\n",
       "  6.524,\n",
       "  1.432235467,\n",
       "  14.9084,\n",
       "  8.429960000000001,\n",
       "  14.919220000000001,\n",
       "  269.487],\n",
       " [65.0,\n",
       "  30.91557669,\n",
       "  97.0,\n",
       "  10.491,\n",
       "  2.5101466,\n",
       "  44.0217,\n",
       "  3.71009,\n",
       "  20.4685,\n",
       "  396.648],\n",
       " [72.0,\n",
       "  29.13631634,\n",
       "  83.0,\n",
       "  10.949000000000002,\n",
       "  2.241625267,\n",
       "  26.8081,\n",
       "  2.78491,\n",
       "  14.76966,\n",
       "  232.018],\n",
       " [57.0,\n",
       "  34.83814777,\n",
       "  95.0,\n",
       "  12.548,\n",
       "  2.9404146669999998,\n",
       "  33.1612,\n",
       "  2.36495,\n",
       "  9.9542,\n",
       "  655.834],\n",
       " [73.0,\n",
       "  37.109375,\n",
       "  134.0,\n",
       "  5.636,\n",
       "  1.862885867,\n",
       "  41.4064,\n",
       "  3.335665,\n",
       "  6.89235,\n",
       "  788.9019999999999],\n",
       " [45.0,\n",
       "  29.38475666,\n",
       "  90.0,\n",
       "  4.713,\n",
       "  1.046286,\n",
       "  23.8479,\n",
       "  6.644245,\n",
       "  15.55625,\n",
       "  621.273],\n",
       " [46.0, 33.18, 92.0, 5.75, 1.304866667, 18.69, 9.16, 8.89, 209.19],\n",
       " [68.0, 35.56, 131.0, 8.15, 2.633536667, 17.87, 11.9, 4.19, 198.4],\n",
       " [75.0, 30.48, 152.0, 7.01, 2.6282826669999997, 50.53, 10.06, 11.73, 99.45],\n",
       " [54.0, 36.05, 119.0, 11.91, 3.495982, 89.27, 8.01, 5.06, 218.28],\n",
       " [45.0, 26.85, 92.0, 3.33, 0.755688, 54.68, 12.1, 10.96, 268.23],\n",
       " [62.0, 26.84, 100.0, 4.53, 1.1174, 12.45, 21.42, 7.32, 330.16],\n",
       " [65.0, 32.05, 97.0, 5.73, 1.370998, 61.48, 22.54, 10.33, 314.05],\n",
       " [72.0, 25.59, 82.0, 2.82, 0.570392, 24.96, 33.75, 3.27, 392.46],\n",
       " [86.0, 27.18, 138.0, 19.91, 6.7773639999999995, 90.28, 14.11, 4.35, 90.09]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the features...\n",
    "x = data.drop(['Classification'], axis=1).values.tolist()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the labels\n",
    "y = data['Classification'].values.tolist()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y)):\n",
    "    if y[i] == 1:\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = 1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57979363, -0.81667527, -1.23922225, ..., -0.07022151,\n",
       "        -0.54551749, -0.34125061],\n",
       "       [ 1.60182096, -1.37875056, -0.25829943, ..., -0.69734988,\n",
       "        -0.86421418, -0.1912238 ],\n",
       "       [ 1.53948912, -0.89176446, -0.30288683, ...,  1.79799836,\n",
       "        -0.4416602 ,  0.05821407],\n",
       "       ...,\n",
       "       [ 0.47984774,  0.89385486, -0.03536242, ...,  1.81384272,\n",
       "        -0.3563202 , -0.64049127],\n",
       "       [ 0.91617066, -0.39854568, -0.70417344, ...,  3.45903808,\n",
       "        -0.92857684, -0.41283214],\n",
       "       [ 1.7888165 , -0.0804471 ,  1.79272102, ...,  0.57664406,\n",
       "        -0.84103616, -1.29074683]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=9, units=16, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  app.launch_new_instance()\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim=16, init='uniform', activation='relu', input_dim=9))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(p=0.1))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim=16, init='uniform', activation='relu'))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(p=0.1))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                160       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 449\n",
      "Trainable params: 449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.4783\n",
      "Epoch 2/150\n",
      "92/92 [==============================] - 0s 22us/step - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 3/150\n",
      "92/92 [==============================] - 0s 22us/step - loss: 0.6931 - acc: 0.5652\n",
      "Epoch 4/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.6929 - acc: 0.5652\n",
      "Epoch 5/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.6928 - acc: 0.5652\n",
      "Epoch 6/150\n",
      "92/92 [==============================] - 0s 23us/step - loss: 0.6927 - acc: 0.5652\n",
      "Epoch 7/150\n",
      "92/92 [==============================] - 0s 38us/step - loss: 0.6926 - acc: 0.5652\n",
      "Epoch 8/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.6925 - acc: 0.5652\n",
      "Epoch 9/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.6924 - acc: 0.5652\n",
      "Epoch 10/150\n",
      "92/92 [==============================] - 0s 25us/step - loss: 0.6923 - acc: 0.5652\n",
      "Epoch 11/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.6922 - acc: 0.5652\n",
      "Epoch 12/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.6921 - acc: 0.5652\n",
      "Epoch 13/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.6920 - acc: 0.5652\n",
      "Epoch 14/150\n",
      "92/92 [==============================] - 0s 44us/step - loss: 0.6919 - acc: 0.5652\n",
      "Epoch 15/150\n",
      "92/92 [==============================] - 0s 38us/step - loss: 0.6917 - acc: 0.5652\n",
      "Epoch 16/150\n",
      "92/92 [==============================] - 0s 32us/step - loss: 0.6917 - acc: 0.5652\n",
      "Epoch 17/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.6915 - acc: 0.5652\n",
      "Epoch 18/150\n",
      "92/92 [==============================] - 0s 34us/step - loss: 0.6914 - acc: 0.5652\n",
      "Epoch 19/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.6911 - acc: 0.5652\n",
      "Epoch 20/150\n",
      "92/92 [==============================] - 0s 23us/step - loss: 0.6910 - acc: 0.5652\n",
      "Epoch 21/150\n",
      "92/92 [==============================] - 0s 22us/step - loss: 0.6908 - acc: 0.5652\n",
      "Epoch 22/150\n",
      "92/92 [==============================] - 0s 22us/step - loss: 0.6906 - acc: 0.5652\n",
      "Epoch 23/150\n",
      "92/92 [==============================] - 0s 23us/step - loss: 0.6906 - acc: 0.5652\n",
      "Epoch 24/150\n",
      "92/92 [==============================] - 0s 30us/step - loss: 0.6903 - acc: 0.5652\n",
      "Epoch 25/150\n",
      "92/92 [==============================] - 0s 58us/step - loss: 0.6900 - acc: 0.5652\n",
      "Epoch 26/150\n",
      "92/92 [==============================] - 0s 53us/step - loss: 0.6898 - acc: 0.5652\n",
      "Epoch 27/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.6895 - acc: 0.5652\n",
      "Epoch 28/150\n",
      "92/92 [==============================] - 0s 37us/step - loss: 0.6893 - acc: 0.5652\n",
      "Epoch 29/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.6892 - acc: 0.5652\n",
      "Epoch 30/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.6887 - acc: 0.5652\n",
      "Epoch 31/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.6882 - acc: 0.5652\n",
      "Epoch 32/150\n",
      "92/92 [==============================] - 0s 38us/step - loss: 0.6884 - acc: 0.5652\n",
      "Epoch 33/150\n",
      "92/92 [==============================] - 0s 31us/step - loss: 0.6877 - acc: 0.5652\n",
      "Epoch 34/150\n",
      "92/92 [==============================] - 0s 39us/step - loss: 0.6874 - acc: 0.5652\n",
      "Epoch 35/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.6867 - acc: 0.5652\n",
      "Epoch 36/150\n",
      "92/92 [==============================] - 0s 23us/step - loss: 0.6860 - acc: 0.5652\n",
      "Epoch 37/150\n",
      "92/92 [==============================] - 0s 44us/step - loss: 0.6859 - acc: 0.5652\n",
      "Epoch 38/150\n",
      "92/92 [==============================] - 0s 22us/step - loss: 0.6855 - acc: 0.5652\n",
      "Epoch 39/150\n",
      "92/92 [==============================] - 0s 23us/step - loss: 0.6846 - acc: 0.5652\n",
      "Epoch 40/150\n",
      "92/92 [==============================] - 0s 25us/step - loss: 0.6832 - acc: 0.5652\n",
      "Epoch 41/150\n",
      "92/92 [==============================] - 0s 50us/step - loss: 0.6828 - acc: 0.5652\n",
      "Epoch 42/150\n",
      "92/92 [==============================] - 0s 40us/step - loss: 0.6825 - acc: 0.5652\n",
      "Epoch 43/150\n",
      "92/92 [==============================] - 0s 29us/step - loss: 0.6819 - acc: 0.5652\n",
      "Epoch 44/150\n",
      "92/92 [==============================] - 0s 86us/step - loss: 0.6812 - acc: 0.5652\n",
      "Epoch 45/150\n",
      "92/92 [==============================] - 0s 44us/step - loss: 0.6801 - acc: 0.5652\n",
      "Epoch 46/150\n",
      "92/92 [==============================] - 0s 38us/step - loss: 0.6796 - acc: 0.5652\n",
      "Epoch 47/150\n",
      "92/92 [==============================] - 0s 39us/step - loss: 0.6780 - acc: 0.5652\n",
      "Epoch 48/150\n",
      "92/92 [==============================] - 0s 47us/step - loss: 0.6773 - acc: 0.5652\n",
      "Epoch 49/150\n",
      "92/92 [==============================] - 0s 43us/step - loss: 0.6760 - acc: 0.5652\n",
      "Epoch 50/150\n",
      "92/92 [==============================] - 0s 66us/step - loss: 0.6749 - acc: 0.5652\n",
      "Epoch 51/150\n",
      "92/92 [==============================] - 0s 46us/step - loss: 0.6734 - acc: 0.5761\n",
      "Epoch 52/150\n",
      "92/92 [==============================] - 0s 48us/step - loss: 0.6729 - acc: 0.5543\n",
      "Epoch 53/150\n",
      "92/92 [==============================] - 0s 55us/step - loss: 0.6715 - acc: 0.5761\n",
      "Epoch 54/150\n",
      "92/92 [==============================] - 0s 52us/step - loss: 0.6696 - acc: 0.5761\n",
      "Epoch 55/150\n",
      "92/92 [==============================] - 0s 66us/step - loss: 0.6684 - acc: 0.6196\n",
      "Epoch 56/150\n",
      "92/92 [==============================] - 0s 28us/step - loss: 0.6669 - acc: 0.6196\n",
      "Epoch 57/150\n",
      "92/92 [==============================] - 0s 52us/step - loss: 0.6655 - acc: 0.6087\n",
      "Epoch 58/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.6644 - acc: 0.6304\n",
      "Epoch 59/150\n",
      "92/92 [==============================] - 0s 23us/step - loss: 0.6631 - acc: 0.6304\n",
      "Epoch 60/150\n",
      "92/92 [==============================] - 0s 39us/step - loss: 0.6620 - acc: 0.6196\n",
      "Epoch 61/150\n",
      "92/92 [==============================] - 0s 35us/step - loss: 0.6605 - acc: 0.6304\n",
      "Epoch 62/150\n",
      "92/92 [==============================] - 0s 38us/step - loss: 0.6567 - acc: 0.7174\n",
      "Epoch 63/150\n",
      "92/92 [==============================] - 0s 28us/step - loss: 0.6547 - acc: 0.6848\n",
      "Epoch 64/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.6527 - acc: 0.7283\n",
      "Epoch 65/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.6498 - acc: 0.6739\n",
      "Epoch 66/150\n",
      "92/92 [==============================] - 0s 63us/step - loss: 0.6501 - acc: 0.6957\n",
      "Epoch 67/150\n",
      "92/92 [==============================] - 0s 30us/step - loss: 0.6491 - acc: 0.7174\n",
      "Epoch 68/150\n",
      "92/92 [==============================] - 0s 51us/step - loss: 0.6465 - acc: 0.7609\n",
      "Epoch 69/150\n",
      "92/92 [==============================] - 0s 42us/step - loss: 0.6430 - acc: 0.7391\n",
      "Epoch 70/150\n",
      "92/92 [==============================] - 0s 33us/step - loss: 0.6428 - acc: 0.7609\n",
      "Epoch 71/150\n",
      "92/92 [==============================] - 0s 33us/step - loss: 0.6380 - acc: 0.7717\n",
      "Epoch 72/150\n",
      "92/92 [==============================] - 0s 49us/step - loss: 0.6369 - acc: 0.7609\n",
      "Epoch 73/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.6326 - acc: 0.8152\n",
      "Epoch 74/150\n",
      "92/92 [==============================] - 0s 34us/step - loss: 0.6314 - acc: 0.7935\n",
      "Epoch 75/150\n",
      "92/92 [==============================] - 0s 29us/step - loss: 0.6318 - acc: 0.7935\n",
      "Epoch 76/150\n",
      "92/92 [==============================] - 0s 47us/step - loss: 0.6261 - acc: 0.7609\n",
      "Epoch 77/150\n",
      "92/92 [==============================] - 0s 25us/step - loss: 0.6244 - acc: 0.7826\n",
      "Epoch 78/150\n",
      "92/92 [==============================] - 0s 37us/step - loss: 0.6169 - acc: 0.8370\n",
      "Epoch 79/150\n",
      "92/92 [==============================] - 0s 29us/step - loss: 0.6180 - acc: 0.8370\n",
      "Epoch 80/150\n",
      "92/92 [==============================] - 0s 43us/step - loss: 0.6187 - acc: 0.8043\n",
      "Epoch 81/150\n",
      "92/92 [==============================] - 0s 25us/step - loss: 0.6116 - acc: 0.8043\n",
      "Epoch 82/150\n",
      "92/92 [==============================] - 0s 31us/step - loss: 0.6099 - acc: 0.8043\n",
      "Epoch 83/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.6085 - acc: 0.8261\n",
      "Epoch 84/150\n",
      "92/92 [==============================] - 0s 44us/step - loss: 0.6005 - acc: 0.8261\n",
      "Epoch 85/150\n",
      "92/92 [==============================] - 0s 30us/step - loss: 0.6007 - acc: 0.8370\n",
      "Epoch 86/150\n",
      "92/92 [==============================] - 0s 35us/step - loss: 0.6011 - acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/150\n",
      "92/92 [==============================] - 0s 38us/step - loss: 0.5923 - acc: 0.8152\n",
      "Epoch 88/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.5902 - acc: 0.8152\n",
      "Epoch 89/150\n",
      "92/92 [==============================] - 0s 37us/step - loss: 0.5898 - acc: 0.8043\n",
      "Epoch 90/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.5882 - acc: 0.8152\n",
      "Epoch 91/150\n",
      "92/92 [==============================] - 0s 25us/step - loss: 0.5819 - acc: 0.7935\n",
      "Epoch 92/150\n",
      "92/92 [==============================] - 0s 39us/step - loss: 0.5784 - acc: 0.7935\n",
      "Epoch 93/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.5789 - acc: 0.8152\n",
      "Epoch 94/150\n",
      "92/92 [==============================] - 0s 28us/step - loss: 0.5751 - acc: 0.7826\n",
      "Epoch 95/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.5744 - acc: 0.7717\n",
      "Epoch 96/150\n",
      "92/92 [==============================] - 0s 38us/step - loss: 0.5680 - acc: 0.7935\n",
      "Epoch 97/150\n",
      "92/92 [==============================] - 0s 45us/step - loss: 0.5694 - acc: 0.8043\n",
      "Epoch 98/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.5654 - acc: 0.7935\n",
      "Epoch 99/150\n",
      "92/92 [==============================] - 0s 22us/step - loss: 0.5582 - acc: 0.7935\n",
      "Epoch 100/150\n",
      "92/92 [==============================] - 0s 38us/step - loss: 0.5577 - acc: 0.8043\n",
      "Epoch 101/150\n",
      "92/92 [==============================] - 0s 25us/step - loss: 0.5476 - acc: 0.8043\n",
      "Epoch 102/150\n",
      "92/92 [==============================] - 0s 30us/step - loss: 0.5516 - acc: 0.8370\n",
      "Epoch 103/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.5475 - acc: 0.7935\n",
      "Epoch 104/150\n",
      "92/92 [==============================] - 0s 34us/step - loss: 0.5453 - acc: 0.7935\n",
      "Epoch 105/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.5384 - acc: 0.8152\n",
      "Epoch 106/150\n",
      "92/92 [==============================] - 0s 28us/step - loss: 0.5435 - acc: 0.7609\n",
      "Epoch 107/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.5297 - acc: 0.8043\n",
      "Epoch 108/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.5293 - acc: 0.8261\n",
      "Epoch 109/150\n",
      "92/92 [==============================] - 0s 28us/step - loss: 0.5355 - acc: 0.7826\n",
      "Epoch 110/150\n",
      "92/92 [==============================] - 0s 25us/step - loss: 0.5270 - acc: 0.7935\n",
      "Epoch 111/150\n",
      "92/92 [==============================] - 0s 30us/step - loss: 0.5261 - acc: 0.8152\n",
      "Epoch 112/150\n",
      "92/92 [==============================] - 0s 36us/step - loss: 0.5235 - acc: 0.8261\n",
      "Epoch 113/150\n",
      "92/92 [==============================] - 0s 43us/step - loss: 0.5168 - acc: 0.7826\n",
      "Epoch 114/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.5232 - acc: 0.8043\n",
      "Epoch 115/150\n",
      "92/92 [==============================] - 0s 29us/step - loss: 0.5122 - acc: 0.7935\n",
      "Epoch 116/150\n",
      "92/92 [==============================] - 0s 31us/step - loss: 0.5071 - acc: 0.7935\n",
      "Epoch 117/150\n",
      "92/92 [==============================] - 0s 31us/step - loss: 0.5131 - acc: 0.7935\n",
      "Epoch 118/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.4981 - acc: 0.8043\n",
      "Epoch 119/150\n",
      "92/92 [==============================] - 0s 22us/step - loss: 0.5061 - acc: 0.8152\n",
      "Epoch 120/150\n",
      "92/92 [==============================] - 0s 40us/step - loss: 0.4973 - acc: 0.8152\n",
      "Epoch 121/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.4993 - acc: 0.7826\n",
      "Epoch 122/150\n",
      "92/92 [==============================] - 0s 31us/step - loss: 0.4931 - acc: 0.7935\n",
      "Epoch 123/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.4923 - acc: 0.7717\n",
      "Epoch 124/150\n",
      "92/92 [==============================] - 0s 39us/step - loss: 0.4822 - acc: 0.8261\n",
      "Epoch 125/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.4888 - acc: 0.8043\n",
      "Epoch 126/150\n",
      "92/92 [==============================] - 0s 31us/step - loss: 0.4873 - acc: 0.7826\n",
      "Epoch 127/150\n",
      "92/92 [==============================] - 0s 25us/step - loss: 0.4812 - acc: 0.7935\n",
      "Epoch 128/150\n",
      "92/92 [==============================] - 0s 35us/step - loss: 0.4739 - acc: 0.8152\n",
      "Epoch 129/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.4700 - acc: 0.7826\n",
      "Epoch 130/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.4770 - acc: 0.8261\n",
      "Epoch 131/150\n",
      "92/92 [==============================] - 0s 32us/step - loss: 0.4714 - acc: 0.7935\n",
      "Epoch 132/150\n",
      "92/92 [==============================] - 0s 22us/step - loss: 0.4685 - acc: 0.7826\n",
      "Epoch 133/150\n",
      "92/92 [==============================] - 0s 32us/step - loss: 0.4458 - acc: 0.8043\n",
      "Epoch 134/150\n",
      "92/92 [==============================] - 0s 24us/step - loss: 0.4692 - acc: 0.8152\n",
      "Epoch 135/150\n",
      "92/92 [==============================] - 0s 45us/step - loss: 0.4583 - acc: 0.7935\n",
      "Epoch 136/150\n",
      "92/92 [==============================] - 0s 28us/step - loss: 0.4566 - acc: 0.7935\n",
      "Epoch 137/150\n",
      "92/92 [==============================] - 0s 29us/step - loss: 0.4682 - acc: 0.8043\n",
      "Epoch 138/150\n",
      "92/92 [==============================] - 0s 25us/step - loss: 0.4629 - acc: 0.7826\n",
      "Epoch 139/150\n",
      "92/92 [==============================] - 0s 25us/step - loss: 0.4499 - acc: 0.8043\n",
      "Epoch 140/150\n",
      "92/92 [==============================] - 0s 25us/step - loss: 0.4412 - acc: 0.7717\n",
      "Epoch 141/150\n",
      "92/92 [==============================] - 0s 29us/step - loss: 0.4495 - acc: 0.7500\n",
      "Epoch 142/150\n",
      "92/92 [==============================] - 0s 32us/step - loss: 0.4524 - acc: 0.7826\n",
      "Epoch 143/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.4471 - acc: 0.8370\n",
      "Epoch 144/150\n",
      "92/92 [==============================] - 0s 28us/step - loss: 0.4470 - acc: 0.7935\n",
      "Epoch 145/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.4312 - acc: 0.8043\n",
      "Epoch 146/150\n",
      "92/92 [==============================] - 0s 33us/step - loss: 0.4250 - acc: 0.8370\n",
      "Epoch 147/150\n",
      "92/92 [==============================] - 0s 27us/step - loss: 0.4429 - acc: 0.7826\n",
      "Epoch 148/150\n",
      "92/92 [==============================] - 0s 26us/step - loss: 0.4335 - acc: 0.8043\n",
      "Epoch 149/150\n",
      "92/92 [==============================] - 0s 28us/step - loss: 0.4346 - acc: 0.8261\n",
      "Epoch 150/150\n",
      "92/92 [==============================] - 0s 44us/step - loss: 0.4379 - acc: 0.7935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x137e505c0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(xTrain, yTrain, batch_size=100, nb_epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(xTest)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(yTest, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 70.83333333333334%\n"
     ]
    }
   ],
   "source": [
    "print(\"Our accuracy is {}%\".format((float(cm[0][0] + cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1]))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
